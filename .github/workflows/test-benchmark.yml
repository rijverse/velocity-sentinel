name: Test Benchmark

on:
  workflow_dispatch:
    inputs:
      runner_type:
        description: 'Runner type for testing'
        required: false
        default: 'ubuntu-latest'
        type: choice
        options:
          - 'ubuntu-latest'
          - 'ubuntu-latest-4-cores'
          - 'ubuntu-latest-8-cores'

jobs:
  test-benchmark:
    runs-on: ${{ github.event.inputs.runner_type || 'ubuntu-latest' }}
    
    strategy:
      matrix:
        node-version: [22.x]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Runner Context
      run: |
        set -e
        echo "üèÉ‚Äç‚ôÇÔ∏è Running on: ${{ github.event.inputs.runner_type || 'ubuntu-latest' }}"
        echo "üîß Node.js Version: ${{ matrix.node-version }}"
        echo "üìä System Info:"
        echo "  - OS: ${{ runner.os }}"
        echo "  - Architecture: ${{ runner.arch }}"
        
        if [ "${{ runner.os }}" = "Linux" ]; then
          echo "  - CPU Cores: $(nproc)"
          echo "  - Memory: $(free -h | awk '/^Mem:/ {print $2}')"
        fi
        
        echo "RUNNER_TYPE=${{ github.event.inputs.runner_type || 'ubuntu-latest' }}" >> $GITHUB_ENV
      
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'yarn'
    
    - name: Record start time
      run: |
        set -e
        echo "WORKFLOW_START_TIME=$(date +%s)" >> $GITHUB_ENV
    
    - name: Install dependencies
      run: |
        set -e
        echo "‚è±Ô∏è Installing dependencies..."
        INSTALL_START=$(date +%s)
        yarn install --frozen-lockfile
        INSTALL_END=$(date +%s)
        INSTALL_DURATION=$((INSTALL_END - INSTALL_START))
        if ! [[ "$INSTALL_DURATION" =~ ^[0-9]+$ ]]; then
          echo "Error: INSTALL_DURATION is not a number!" >&2
          exit 1
        fi
        echo "üì¶ Dependencies installed in ${INSTALL_DURATION}s"
        echo "INSTALL_DURATION=${INSTALL_DURATION}" >> $GITHUB_ENV
    
    - name: Run unit tests with timing
      run: |
        set -e
        echo "‚è±Ô∏è Starting unit test execution..."
        TEST_START=$(date +%s)
        yarn test --testNamePattern="^(?!.*Performance Benchmarks)" --verbose --testTimeout=30000
        TEST_END=$(date +%s)
        TEST_DURATION=$((TEST_END - TEST_START))
        if ! [[ "$TEST_DURATION" =~ ^[0-9]+$ ]]; then
          echo "Error: TEST_DURATION is not a number!" >&2
          exit 1
        fi
        echo "‚úÖ Unit tests completed in ${TEST_DURATION}s"
        echo "TEST_DURATION=${TEST_DURATION}" >> $GITHUB_ENV
    
    - name: Run performance benchmarks
      run: |
        set -e
        echo "‚è±Ô∏è Running performance benchmarks..."
        PERF_START=$(date +%s)
        yarn test --testNamePattern="Performance Benchmarks" --verbose --testTimeout=180000
        PERF_END=$(date +%s)
        PERF_DURATION=$((PERF_END - PERF_START))
        if ! [[ "$PERF_DURATION" =~ ^[0-9]+$ ]]; then
          echo "Error: PERF_DURATION is not a number!" >&2
          exit 1
        fi
        echo "üöÄ Performance benchmarks completed in ${PERF_DURATION}s"
        echo "PERF_DURATION=${PERF_DURATION}" >> $GITHUB_ENV
    
    - name: Run tests with coverage
      run: |
        set -e
        echo "‚è±Ô∏è Running tests with coverage..."
        COVERAGE_START=$(date +%s)
        yarn test:coverage
        COVERAGE_END=$(date +%s)
        COVERAGE_DURATION=$((COVERAGE_END - COVERAGE_START))
        if ! [[ "$COVERAGE_DURATION" =~ ^[0-9]+$ ]]; then
          echo "Error: COVERAGE_DURATION is not a number!" >&2
          exit 1
        fi
        echo "üìä Coverage analysis completed in ${COVERAGE_DURATION}s"
        echo "COVERAGE_DURATION=${COVERAGE_DURATION}" >> $GITHUB_ENV
    
    - name: Calculate total workflow time
      run: |
        set -e
        WORKFLOW_END_TIME=$(date +%s)
        TOTAL_DURATION=$((WORKFLOW_END_TIME - WORKFLOW_START_TIME))
        if ! [[ "$TOTAL_DURATION" =~ ^[0-9]+$ ]]; then
          echo "Error: TOTAL_DURATION is not a number!" >&2
          exit 1
        fi
        
        # Calculate performance score relative to baseline
        BASELINE_TIME=300  # Expected time for ubuntu-latest
        PERFORMANCE_SCORE=$((BASELINE_TIME * 100 / TOTAL_DURATION))
        echo "PERFORMANCE_SCORE=${PERFORMANCE_SCORE}" >> $GITHUB_ENV
        
        echo "## üìä Runner Performance Summary" >> $GITHUB_STEP_SUMMARY
        echo "| Step | Duration |" >> $GITHUB_STEP_SUMMARY
        echo "|------|----------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Runner Type** | ${{ env.RUNNER_TYPE }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Dependencies Install | ${INSTALL_DURATION}s |" >> $GITHUB_STEP_SUMMARY
        echo "| Unit Tests | ${TEST_DURATION}s |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance Benchmarks | ${PERF_DURATION}s |" >> $GITHUB_STEP_SUMMARY
        echo "| Coverage Analysis | ${COVERAGE_DURATION}s |" >> $GITHUB_STEP_SUMMARY
        echo "| **Total Workflow Time** | **${TOTAL_DURATION}s** |" >> $GITHUB_STEP_SUMMARY
        echo "| **Performance Score** | **${PERFORMANCE_SCORE}** |" >> $GITHUB_STEP_SUMMARY
        
        echo "### üîç Environment Details" >> $GITHUB_STEP_SUMMARY
        echo "- **Node.js Version**: ${{ matrix.node-version }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Runner Type**: ${{ env.RUNNER_TYPE }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Workflow Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        
        # Performance rating
        if [ $PERFORMANCE_SCORE -gt 150 ]; then
          echo "- **Performance Rating**: üöÄ Excellent" >> $GITHUB_STEP_SUMMARY
        elif [ $PERFORMANCE_SCORE -gt 120 ]; then
          echo "- **Performance Rating**: ‚ö° Very Good" >> $GITHUB_STEP_SUMMARY
        elif [ $PERFORMANCE_SCORE -gt 100 ]; then
          echo "- **Performance Rating**: ‚úÖ Good" >> $GITHUB_STEP_SUMMARY
        elif [ $PERFORMANCE_SCORE -gt 80 ]; then
          echo "- **Performance Rating**: ‚ö†Ô∏è Average" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Performance Rating**: üêå Below Average" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report-${{ env.RUNNER_TYPE }}-node-${{ matrix.node-version }}
        path: |
          coverage/
          *.log
        retention-days: 30
    
    - name: Performance threshold validation
      run: |
        set -e
        echo "üéØ Validating performance thresholds for ${{ env.RUNNER_TYPE }}..."
        
        # Define performance thresholds based on runner type
        case "${{ env.RUNNER_TYPE }}" in
          "ubuntu-latest")
            MAX_INSTALL_TIME=120
            MAX_TEST_TIME=60
            MAX_PERF_TIME=45
            MAX_COVERAGE_TIME=80
            MAX_TOTAL_TIME=300
            ;;
          "ubuntu-latest-4-cores")
            MAX_INSTALL_TIME=80
            MAX_TEST_TIME=40
            MAX_PERF_TIME=30
            MAX_COVERAGE_TIME=60
            MAX_TOTAL_TIME=200
            ;;
          "ubuntu-latest-8-cores")
            MAX_INSTALL_TIME=60
            MAX_TEST_TIME=30
            MAX_PERF_TIME=25
            MAX_COVERAGE_TIME=45
            MAX_TOTAL_TIME=150
            ;;
          *)
            # Default thresholds
            MAX_INSTALL_TIME=120
            MAX_TEST_TIME=60
            MAX_PERF_TIME=45
            MAX_COVERAGE_TIME=80
            MAX_TOTAL_TIME=300
            ;;
        esac
        
        # Check each threshold
        THRESHOLD_VIOLATIONS=0
        
        if [ $INSTALL_DURATION -gt $MAX_INSTALL_TIME ]; then
          echo "‚ùå Installation time exceeded threshold: ${INSTALL_DURATION}s > ${MAX_INSTALL_TIME}s"
          THRESHOLD_VIOLATIONS=$((THRESHOLD_VIOLATIONS + 1))
        fi
        
        if [ $TEST_DURATION -gt $MAX_TEST_TIME ]; then
          echo "‚ùå Test execution time exceeded threshold: ${TEST_DURATION}s > ${MAX_TEST_TIME}s"
          THRESHOLD_VIOLATIONS=$((THRESHOLD_VIOLATIONS + 1))
        fi
        
        if [ $PERF_DURATION -gt $MAX_PERF_TIME ]; then
          echo "‚ùå Performance benchmark time exceeded threshold: ${PERF_DURATION}s > ${MAX_PERF_TIME}s"
          THRESHOLD_VIOLATIONS=$((THRESHOLD_VIOLATIONS + 1))
        fi
        
        if [ $COVERAGE_DURATION -gt $MAX_COVERAGE_TIME ]; then
          echo "‚ùå Coverage analysis time exceeded threshold: ${COVERAGE_DURATION}s > ${MAX_COVERAGE_TIME}s"
          THRESHOLD_VIOLATIONS=$((THRESHOLD_VIOLATIONS + 1))
        fi
        
        if [ $TOTAL_DURATION -gt $MAX_TOTAL_TIME ]; then
          echo "‚ùå Total workflow time exceeded threshold: ${TOTAL_DURATION}s > ${MAX_TOTAL_TIME}s"
          THRESHOLD_VIOLATIONS=$((THRESHOLD_VIOLATIONS + 1))
        fi
        
        if [ $THRESHOLD_VIOLATIONS -eq 0 ]; then
          echo "‚úÖ All performance thresholds passed for ${{ env.RUNNER_TYPE }}!"
        else
          echo "‚ö†Ô∏è ${THRESHOLD_VIOLATIONS} performance threshold(s) exceeded"
          echo "This may indicate performance regression or need for threshold adjustment"
          # TODO: Integrate notification or fail workflow if needed
        fi
        
        echo ""
        echo "üìä Performance Summary for ${{ env.RUNNER_TYPE }}:"
        echo "  - Installation: ${INSTALL_DURATION}s / ${MAX_INSTALL_TIME}s $([ $INSTALL_DURATION -le $MAX_INSTALL_TIME ] && echo '‚úÖ' || echo '‚ùå')"
        echo "  - Unit Tests: ${TEST_DURATION}s / ${MAX_TEST_TIME}s $([ $TEST_DURATION -le $MAX_TEST_TIME ] && echo '‚úÖ' || echo '‚ùå')"
        echo "  - Benchmarks: ${PERF_DURATION}s / ${MAX_PERF_TIME}s $([ $PERF_DURATION -le $MAX_PERF_TIME ] && echo '‚úÖ' || echo '‚ùå')"
        echo "  - Coverage: ${COVERAGE_DURATION}s / ${MAX_COVERAGE_TIME}s $([ $COVERAGE_DURATION -le $MAX_COVERAGE_TIME ] && echo '‚úÖ' || echo '‚ùå')"
        echo "  - Total: ${TOTAL_DURATION}s / ${MAX_TOTAL_TIME}s $([ $TOTAL_DURATION -le $MAX_TOTAL_TIME ] && echo '‚úÖ' || echo '‚ùå')"
        echo "  - Performance Score: ${PERFORMANCE_SCORE}"